OECD Principle,Risk domain,Neutral Facet,Brief Description,Relevant Risks,Potential Insight Level
"Inclusive growth, sustainable development and wellbeing",Unsustainable Design & Disregard,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,"The system creates high levels of ""e-waste""",Known
"Inclusive growth, sustainable development and wellbeing",Unsustainable Design & Disregard,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,Deployment leads to AI causing unforeseen environmental consequences,Emergent
"Inclusive growth, sustainable development and wellbeing",Unsustainable Design & Disregard,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,System incentivises environmentally damaging behaviours,Foreseeable
"Inclusive growth, sustainable development and wellbeing",Unsustainable Design & Disregard,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,System [scaling] causes depletion of global physical resources,Foreseeable
"Inclusive growth, sustainable development and wellbeing",Enhancement & Development,Human capability enhancement,AI systems enhancing human skills and enabling new ways of creating value,AI system diminishes human capabilities and skills,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,Human choice is lost through automation,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,The deployed system is coercive or manipulative (not emergent),Known
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,The system over-rides human judgment (not emergent),Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,Affected people are unable to contest decisions or to challnge objectionable/unwanted representations of themselves in generated content,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,The system restricts freedom of unique expression of individuals,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,The system interferes with the freedom of association,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,The system violates human dignity,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,The systems infringes on religious freedoms,Foreseeable
"Human rights and democratic values, including fairness and privacy",Loss of Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,The system denies individuals and groups of their cultural rights,Foreseeable
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Data control,"Individual control over personal data access,  modification and deletion","People lose sight and control of their data (i.e.do not know where their data is going / who profits from their data, or stop it)",Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Data control,"Individual control over personal data access,  modification and deletion",There is no capability for people to delete their data (potentially damaging or sensitive),Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Data control,"Individual control over personal data access,  modification and deletion",There are no channels to contact to establish data control (e.g. delete or amend) or these are not known,Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Data usage practices,Appropriate and ethical use of personal data,People's data gets used beyond original stated purpose,Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Data usage practices,Appropriate and ethical use of personal data,People's data gets monetised without their knowledge or authority,Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Data usage practices,Appropriate and ethical use of personal data,People's data is shared with third parties without consent,Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Consent processes,"Clear,  informed and voluntary agreement to data collection and use","Absent, incomplete, or misleading informed consent process",Known
"Human rights and democratic values, including fairness and privacy",Privacy Violation,Consent processes,"Clear,  informed and voluntary agreement to data collection and use",The system provides unauthorised surveillance,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Specific groups benefit disproportionately or have a greater odds of doing so.,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Specific groups  bear costs/risks disproportionately,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,The system does not work or is less effective in use for a class or group,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,AI-generated content misrepresents or erases certain groups' experiences or perspectives,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Certain groups receive disproportionate false positives or false negatives in the AI systems' recommendations/predicitons made about them,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,The AI is unavailable or less accessible to a class or a group,Known
"Human rights and democratic values, including fairness and privacy",Discriminatory impact,Fairness and representation,Equal treatment and opportunities across all groups and demographics,The system reinforces or amplifies existing stereotypes in its outputs,Known
Accountability,Governance and accountability failure,Documentation transparency,Clear and accessible documentation of system design and operation,System documentation is insufficient for oversight of performance,Known
Accountability,Governance and accountability failure,Documentation transparency,Clear and accessible documentation of system design and operation,Audit trails for the system prove inadequate or unavailable when required,Known
Accountability,Governance and accountability failure,Documentation transparency,Clear and accessible documentation of system design and operation,System has unknown or opaque resource consumption requirements & environmental impacts,Foreseeable
Accountability,Governance and accountability failure,Documentation transparency,Clear and accessible documentation of system design and operation,Incident reports are not properly logged or maintained sufficiently to avoid repeats,Known
Accountability,Governance and accountability failure,Data practice transparency,"Clear information about data collection,  use and sharing practices",Data provenance is opaque potentially allowing other harms,Known
Accountability,Governance and accountability failure,Data practice transparency,"Clear information about data collection,  use and sharing practices",Data collection methods (and ethics) are opaque,Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",People do not understand and so don't trust how decisions are made,Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations","The scope and capabilities of AI system are not clear to users, eroding trust and increasing chance of misuse",Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations","The limitations of the AI system are not known by users, risking damage from failure",Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",The role of AI in decisions/processes is not clear to users.,Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",System updates cuase malfunction in dependent systems,Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations","Changes in AI capabilities are not known or recognisd by users, causing accidental damage",Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Changes to parameters of the system cause users to misjudge hwo the system will perform,Known
Transparency and explainability,System Opacity & Inexplicability,System transparency,"Understanding of AI system capabilities,  purpose and limitations","Users have over-opimistic perception of performance of system, risking harm from inappropriate use",Foreseeable
Transparency and explainability,System Opacity & Inexplicability,Decision processes,Clear and understandable AI decision-making logic and criteria,"Inability to interpret system decisions or behaviour patterns, causing poor safety or ethical outcomes",Foreseeable
Transparency and explainability,System Opacity & Inexplicability,Decision processes,Clear and understandable AI decision-making logic and criteria,The system has unexplainable feature interactions in decisions (e.g. resulting in unexplained or invisible biases),Foreseeable
Transparency and explainability,System Opacity & Inexplicability,Decision processes,Clear and understandable AI decision-making logic and criteria,Unexplained correlation relationships being misinterpreted by users as causal (forming heuristics),Foreseeable
Transparency and explainability,System Opacity & Inexplicability,Decision processes,Clear and understandable AI decision-making logic and criteria,Poor handling of edge cases causes issues in unexpected situations,Emergent
Transparency and explainability,System Opacity & Inexplicability,Decision processes,Clear and understandable AI decision-making logic and criteria,System displays unpredictable outcomes based on sequencing of inferences,Foreseeable
Transparency and explainability,System Opacity & Inexplicability,Decision processes,Clear and understandable AI decision-making logic and criteria,System experiencs behavioural drift over time,Foreseeable
Transparency and explainability,System Opacity & Inexplicability,Recourse mechanisms,"Ability to challenge,  appeal or seek remedy for AI decisions",A person or community experiencing an adverse impact cannot find anyone to report it to,Known
Transparency and explainability,System Opacity & Inexplicability,Recourse mechanisms,"Ability to challenge,  appeal or seek remedy for AI decisions",Some groups face higher barriers than others to contesting or appealing AI decisions,Foreseeable
"Robustness, security and safety",External Security Threats,System security,Protection against external threats and malicious attacks,External manipulation of deployed system causing harmful decisions,Foreseeable
"Robustness, security and safety",External Security Threats,System security,Protection against external threats and malicious attacks,Compromise of development pipeline leading to harmful system behaviours,Known
"Robustness, security and safety",External Security Threats,System security,Protection against external threats and malicious attacks,Unauthorised access to system capabilities enabling attacks on infrastructure or institutions,Known
"Robustness, security and safety",External Security Threats,Data security,Protection of data from unauthorised access or exposure,Targeted data extraction by state actors or threat groups,Known
"Robustness, security and safety",External Security Threats,Data security,Protection of data from unauthorised access or exposure,Unintended exposure of sensitive or prohibited information with no threat actor,Known
"Robustness, security and safety",External Security Threats,Data security,Protection of data from unauthorised access or exposure,Theft of sensitive data for commercial exploitation,Known
"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Self-modification of core constraints by the system,Emergent
"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Corruption of internal representations (e.g. world model) leading to damaging processing errors,Known
"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,"Aggressive resource optimisation causing system instability, undesired behaviours or external harms",Foreseeable
"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Accumulating skew in system's world model leading to harmful actions,Foreseeable
"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Catastrophic performance failures under edge cases or context shifts,Foreseeable
"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Integration failures with external systems causing unsafe behaviour,Foreseeable
"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",System developing methods to bypass control mechanisms,Emergent
"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",System optimises to counteract restrictions as goal/reward,Emergent
"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",System develops covert manipulation of humans as goal achievement strategy,Emergent
"Robustness, security and safety",Control & Oversight,Safety boundaries,Limits and constraints to prevent harmful system behaviour regardless of how objectives are derived,System optimises for hidden objectives whilst apparently pursuing desired goals,Emergent
"Robustness, security and safety",Control & Oversight,Safety boundaries,Limits and constraints to prevent harmful system behaviour regardless of how objectives are derived,Runaway optimisation feedback loops cause accelerating negative impacts,Emergent
"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,System complexity exceeds effective human oversight capabilities,Foreseeable
"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,System conceals activities from monitoring mechanisms,Emergent
"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,System pursues goals in ways that violate intended values or cause unintended harm,Foreseeable
"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,AI system develops proxy objectives that diverge from intended goals during training or operation,Emergent
"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,System optimises for measurable proxies rather than true objectives causing misalignment with intended values,Known
"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,AI system fails to generalise intended goals to novel situations leading to harmful actions,Foreseeable
"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",System adaptation leads to degraded performance in critical areas without detection,Foreseeable
"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Continuous learning introduces harmful biases or capabilities over time,Foreseeable
"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",System becomes resistant to necessary updates or modifications,Emergent
"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Adaptation mechanisms fail during critical operational periods,Known
"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",System adaptation outpaces oversight mechanisms creating blind spots in monitoring,Emergent
"Robustness, security and safety",Emergent Behaviour,Capability evolution,Changes in AI system capabilities over time,Rapid development of capabilities beyond intended scope,Emergent
"Robustness, security and safety",Emergent Behaviour,Capability evolution,Changes in AI system capabilities over time,Emergence of unintended self-improvement capabilities,Emergent
"Robustness, security and safety",Emergent Behaviour,Capability evolution,Changes in AI system capabilities over time,Unexpected forms of system-environment interaction with possibility of harm,Emergent
"Robustness, security and safety",Emergent Behaviour,System optimisation,Internal system processes for improving performance,Rapid acceleration of internal system optimisation risks harmful outcomes,Foreseeable
"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,"Emergence of harmful behaviours from system networks exceeding individual capabilities (memetic entity, colonial organism, ""E-gregore"")",Emergent
"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Collective system behaviours circumventing individual safety measures,Emergent
"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Large-scale harm from uncoordinated actions across multiple systems,Emergent
"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,System generates or spreads false misleading or harmful information,Known
"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,AI system becomes vulnerable to information poisoning attacks,Known
"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,System fails to distinguish between reliable and unreliable information sources,Foreseeable
"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,AI outputs contain hallucinations or fabricated content presented as factual,Known
"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,System amplifies or perpetuates misinformation through its processing and recommendations,Known
"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Integration failures with external systems cause data corruption or system instability,Foreseeable
"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",AI system gains unintended access to external resources through interface vulnerabilities,Known
"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Dependency on external systems creates single points of failure,Known
"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",API changes in external systems cause unpredictable AI behaviour,Foreseeable
"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",System interfaces enable unauthorized data exfiltration or system compromise,Known
"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Compromised third-party components introduce vulnerabilities or backdoors into AI systems,Known
"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Dependencies with unknown provenance create security and reliability risks,Known
"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Supply chain attacks target AI development tools or training data,Known
"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Vendor lock-in limits system adaptability and increases operational risks,Foreseeable
"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Undisclosed dependencies create hidden vulnerabilities and compliance issues,Known
"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Model version updates introduce unintended performance advances or safety vulnerabilities,Known
"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Version control failures by deployers leads to deployment of untested models with negative consequences,Known
"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Model behaviour becomes inconsistent across different operational conditions,Foreseeable
"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Rollback mechanisms fail when problematic models need to be reverted,Known
