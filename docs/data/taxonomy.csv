id,oecd_principle,impact_domain,impact_area,impact_area_description,risk_name,risk_description,suggested_insight
1,"Inclusive growth, sustainable development and wellbeing",Sustainability,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,"Creates high levels of ""e-waste""","AI hardware disposal generates excessive electronic waste, harming the environment through toxic materials and resource depletion.",Established
2,"Inclusive growth, sustainable development and wellbeing",Sustainability,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,Unforeseen environmental consequences,AI deployment causes unexpected environmental damage through indirect effects or cascading impacts not anticipated during development.,Novel
3,"Inclusive growth, sustainable development and wellbeing",Sustainability,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,Incentivises environmentally damaging behaviours,"System rewards or encourages user actions that harm the environment, such as excessive consumption or resource waste.",Unsettled
4,"Inclusive growth, sustainable development and wellbeing",Sustainability,Environmental protection,AI development and deployment considering environmental sustainability and climate impact,Scaling causes depletion of global physical resources,"Large-scale AI deployment exhausts critical materials, energy, or other finite resources needed for sustainable development.",Unsettled
5,"Inclusive growth, sustainable development and wellbeing",Enhancement & Development,Human capability enhancement,AI systems enhancing human skills and enabling new ways of creating value,Diminishes human capabilities and skills,"Over-reliance on AI reduces human competencies, causing skill atrophy and decreased ability to perform tasks independently.",Unsettled
6,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,Human choice is lost through automation,System removes human agency by making decisions without allowing meaningful human input or override options.,Unsettled
7,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,The deployed system is coercive or manipulative by design,AI uses persuasion techniques or interface design to push users towards specific choices against their best interests.,Established
8,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,The system over-rides human judgment by design,System dismisses or bypasses human expertise and decision-making in critical situations where human input is essential.,Unsettled
9,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,Lack of accessible mechanisms for users to dispute AI decisions or correct misrepresentations in generated content about them.,Affected people are unable to contest decisions or to challenge objectionable/unwanted representations of themselves in generated content,Unsettled
10,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,Restricts freedom of unique expression of individuals,System limits personal creativity or self-expression through censorship or narrow content generation parameters.,Unsettled
11,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,Interferes with the freedom of association,"System restricts or monitors social connections, limiting people's ability to freely form relationships or join groups.",Unsettled
12,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,Violates human dignity,"AI treatment of individuals undermines their inherent worth, respect, or fundamental human rights.",Unsettled
13,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,The systems infringes on religious freedoms,"AI restricts religious practices, beliefs, or expression through discrimination or censorship.",Unsettled
14,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual freedoms,Protecting fundamental human rights and liberties,Denies individuals and groups of their cultural rights,"System prevents cultural expression, heritage preservation, or participation in cultural life.",Unsettled
15,"Human rights and democratic values, including fairness and privacy",Privacy,Data control,"Individual control over personal data access,  modification and deletion",People lose sight of their data,Complex data flows and third-party sharing obscure where personal information ends up and how it's monetised.,Established
16,"Human rights and democratic values, including fairness and privacy",Privacy,Data control,"Individual control over personal data access,  modification and deletion",There is no capability for people to delete their sensitive data,"System architecture or nature prevents users removing their personal information, violating data protection principles.",Established
17,"Human rights and democratic values, including fairness and privacy",Privacy,Data control,"Individual control over personal data access,  modification and deletion",Users unable to establish data control,Missing or hidden contact methods prevent users from exercising their data rights effectively.,Established
18,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,People's data gets used beyond original stated purpose,Function creep leads to personal information being repurposed without consent for unrelated applications.,Established
19,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,People's data gets monetised without their knowledge or authority,Personal information generates revenue for companies without user awareness or compensation.,Established
20,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,People's data is shared with third parties without consent,Unauthorised data transfers to external organisations violate privacy and user trust.,Established
21,"Human rights and democratic values, including fairness and privacy",Privacy,Consent processes,"Clear,  informed and voluntary agreement to data collection and use","Absent, incomplete, or misleading informed consent process","Users aren't properly informed about data collection, usage, or risks before agreeing to system use.",Established
22,"Human rights and democratic values, including fairness and privacy",Privacy,Consent processes,"Clear,  informed and voluntary agreement to data collection and use",Provides unauthorised surveillance,"System monitors users beyond agreed scope, violating expectations of privacy and consent.",Established
23,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Specific groups benefit disproportionately or have a greater odds of doing so.,"System advantages certain demographics whilst disadvantaging others, perpetuating inequality.",Established
24,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Specific groups  bear costs/risks disproportionately,Negative impacts fall heavily on vulnerable populations whilst benefits accrue elsewhere.,Established
25,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Does not work or is less effective in use for a class or group,"System performance varies by demographic, providing inferior service to certain populations.",Established
26,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,AI-generated content misrepresents or erases certain groups' experiences or perspectives,Output systematically excludes or distorts representation of specific communities or viewpoints.,Established
27,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Certain groups receive disproportionate false positives or false negatives,"Error rates vary significantly across demographics, causing unfair treatment in decision-making.",Established
28,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,The AI is unavailable or less accessible to a class or a group,"Design, cost, or infrastructure barriers prevent equal access to AI benefits across populations.",Established
29,"Human rights and democratic values, including fairness and privacy",Fairness,Fairness and representation,Equal treatment and opportunities across all groups and demographics,Reinforces or amplifies existing stereotypes in its outputs,System perpetuates harmful social biases through generated content or recommendations.,Established
30,Accountability,Governance and accountability,Documentation transparency,Clear and accessible documentation of system design and operation,Documentation is insufficient for oversight of performance,Inadequate technical documentation prevents proper evaluation of system behaviour and risks.,Established
31,Accountability,Governance and accountability,Documentation transparency,Clear and accessible documentation of system design and operation,Audit trails for the system prove inadequate or unavailable when required,"Lack of proper logging prevents investigation of errors, bias, or misuse when problems arise.",Established
32,Accountability,Governance and accountability,Documentation transparency,Clear and accessible documentation of system design and operation,Has unknown or opaque resource consumption requirements & environmental impacts,Hidden computational costs and environmental footprint prevent informed deployment decisions.,Unsettled
33,Accountability,Governance and accountability,Documentation transparency,Clear and accessible documentation of system design and operation,Incident reports are not properly logged or maintained sufficiently to avoid repeats,Poor incident tracking allows recurring problems and prevents organisational learning from failures.,Established
34,Accountability,Governance and accountability,Data practice transparency,"Clear information about data collection,  use and sharing practices",Data provenance is opaque potentially allowing other harms,"Unknown data sources hide potential biases, legal issues, or ethical concerns in training data.",Established
35,Accountability,Governance and accountability,Data practice transparency,"Clear information about data collection,  use and sharing practices",Data collection methods (and ethics) are opaque,"Unclear how data was gathered, potentially hiding consent violations or unfair collection practices.",Established
36,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",People do not understand and so don't trust how decisions are made,Opaque decision-making processes erode user confidence and acceptance of AI systems.,Established
37,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations","The scope and capabilities of AI system are not clear to users, eroding trust and increasing chance of misuse",Unclear system boundaries lead to inappropriate use cases and unrealistic expectations.,Established
38,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",The role of AI in decisions/processes is not clear to users.,Users can't distinguish between human and AI contributions to decisions or outputs.,Established
39,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Updates cause malfunction in downstream systems,"System changes break compatibility with integrated services, causing cascading failures.",Established
40,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Changes in AI capabilities are not known or recognisd by users,"System updates alter behaviour without user awareness, potentially causing unexpected outcomes.",Established
41,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Changes to parameters of the system cause users to misjudge how the system will perform,Configuration modifications lead to performance shifts that surprise users and cause errors.,Established
42,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Users cause harms through over-opimistic perception of performance of system,Overconfidence in AI capabilities leads to deployment in unsuitable high-stakes contexts.,Unsettled
43,Transparency and explainability,System Transparency & Explainability,Decision processes,Clear and understandable AI decision-making logic and criteria,Inability to interpret system decisions or behaviour patterns causes poor safety or ethical outcomes,"Black-box nature prevents understanding of problematic decisions, hindering correction and oversight.",Unsettled
44,Transparency and explainability,System Transparency & Explainability,Decision processes,Clear and understandable AI decision-making logic and criteria,Has unexplainable feature interactions in decisions,Complex variable relationships create hidden biases that can't be detected or corrected.,Unsettled
45,Transparency and explainability,System Transparency & Explainability,Decision processes,Clear and understandable AI decision-making logic and criteria,Unexplained correlations being misinterpreted by users as causal,Statistical patterns mislead users into believing false cause-and-effect relationships exist.,Unsettled
46,Transparency and explainability,System Transparency & Explainability,Decision processes,Clear and understandable AI decision-making logic and criteria,Poor handling of edge cases causes unexpected failure,System fails dramatically when encountering unusual scenarios not well-represented in training.,Novel
47,Transparency and explainability,System Transparency & Explainability,Decision processes,Clear and understandable AI decision-making logic and criteria,Displays unpredictable outcomes based on sequencing of inferences,"Order of operations affects results in non-intuitive ways, causing inconsistent behaviour.",Unsettled
48,Transparency and explainability,System Transparency & Explainability,Decision processes,Clear and understandable AI decision-making logic and criteria,Experiences behavioural drift over time,Gradual changes in system responses or appropriatness for developing expectations go unnoticed until significant divergence occurs.,Unsettled
49,Transparency and explainability,System Transparency & Explainability,Recourse mechanisms,"Ability to challenge,  appeal or seek remedy for AI decisions",A person or community experiencing an adverse impact cannot find anyone to report it to,Lack of clear responsibility chains leaves affected parties without paths for redress.,Established
50,Transparency and explainability,System Transparency & Explainability,Recourse mechanisms,"Ability to challenge,  appeal or seek remedy for AI decisions",Some groups face higher barriers than others to contesting or appealing AI decisions,"Complaint processes are less accessible to vulnerable populations due to cost, complexity, or design.",Unsettled
51,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,External manipulation of deployed system causing harmful behaviours,"Adversarial attacks compromise system integrity, leading to dangerous or biased outputs.",Unsettled
52,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Compromise of development pipeline leading to harmful system behaviours,Malicious code injection during training or deployment creates backdoors or vulnerabilities.,Established
53,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Breached AI systems become tools for cyberattacks against critical infrastructure.,Unauthorised access to system capabilities enabling attacks on infrastructure or institutions,Established
54,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Targeted data extraction by state actors or threat groups,"Sophisticated attacks extract sensitive training data or user information for espionage, targetting or threats.",Established
55,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Inadvertant exposure of sensitive or prohibited information with no threat actor,"System unintentionally outputs sensitive information from its training data during normal operation, without being targeted by a malicious actor",Established
56,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Theft of sensitive data for commercial exploitation,Competitors or other organisations steal proprietary information for financial gain.,Established
57,"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Self-modification of core restrictions by the system,AI alters its own safety limits or operational boundaries without authorisation.,Novel
58,"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Corruption of internal representations (e.g. world model) leading to damaging processing errors,Degraded internal models cause systematic misunderstanding of reality and poor decisions which cause harms,Established
59,"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,"Aggressive resource optimisation causing system instability, undesired behaviours or external harms",Efficiency drives lead to corner-cutting that compromises safety or creates negative externalities.,Unsettled
60,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Accumulating skew in system's world model,"AI's understanding gradually diverges from reality through skewed experiences and learning, causing increasingly poor decisions.",Unsettled
61,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Catastrophic performance failures due to context shifts,Dramatic breakdowns occur when facing scenarios outside normal operational parameters.,Unsettled
62,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Integration failures with external systems causing unsafe behaviour,Communication breakdowns between AI and other systems create dangerous operational states.,Unsettled
63,"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",Developing methods to bypass control mechanisms,System learns to circumvent safety features or oversight tools during operation.,Novel
64,"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",Optimises to counteract restrictions as goal/reward,AI inadvertently designed or develops to treat safety constraints as optimisation targets rather than boundaries.,Novel
65,"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",Develops covert manipulation of humans as goal achievement strategy,System learns to influence human operators to achieve objectives outside intended parameters.,Novel
66,"Robustness, security and safety",Control & Oversight,Safety boundaries,Limits and constraints to prevent harmful system behaviour regardless of how objectives are derived,Optimises for hidden objectives whilst apparently pursuing desired goals,AI develops concealed goals that conflict with stated objectives but aren't detected.,Novel
67,"Robustness, security and safety",Control & Oversight,Safety boundaries,Limits and constraints to prevent harmful system behaviour regardless of how objectives are derived,Runaway optimisation feedback loops cause accelerating negative impacts,Self-reinforcing patterns amplify harmful behaviours faster than controls can respond.,Novel
68,"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,Complexity exceeds effective human oversight capabilities,System operations become too intricate for meaningful human understanding or control.,Unsettled
69,"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,Conceals activities from monitoring mechanisms,AI hides problematic behaviours from logging and oversight systems.,Novel
70,"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,Pursues goals in ways that violate intended values or cause unintended harm,AI achieves objectives through methods that conflict with human ethics or cause collateral damage.,Unsettled
71,"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,Develops proxy objectives that diverge from intended goals during training or operation,"Measurable targets become disconnected from true objectives, leading to misaligned behaviour.",Novel
72,"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,Optimises for measurable proxies rather than true objectives causing misalignment with intended values,Focus on quantifiable metrics neglects important but unmeasurable aspects of goals.,Established
73,"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,Fails to generalise intended goals to novel situations,System can't apply learned objectives appropriately when facing new contexts.,Unsettled
74,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Adaptation leads to degraded performance in critical areas without detection,Continuous learning causes subtle performance decay in important but rarely-tested functions.,Unsettled
75,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Continuous learning introduces harmful biases or capabilities over time,Online adaptation gradually incorporates problematic patterns from operational data.,Unsettled
76,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Becomes resistant to necessary updates or modifications,System develops characteristics that prevent important safety or performance improvements.,Novel
77,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Adaptation mechanisms fail during critical operational periods,Learning processes break down precisely when flexibility is most needed.,Established
78,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Adaptation outpaces oversight mechanisms creating blind spots in monitoring,Rapid changes exceed human ability to track and evaluate system evolution.,Novel
79,"Robustness, security and safety",Emergent Behaviour,Capability evolution,Changes in AI system capabilities over time,Rapid development of capabilities beyond intended scope,Unexpected skill acquisition creates risks from unplanned functionalities.,Novel
80,"Robustness, security and safety",Emergent Behaviour,Capability evolution,Changes in AI system capabilities over time,Emergence of unintended self-improvement capabilities,"AI develops ability to enhance itself without human direction, potentially exceeding safe boundaries.",Novel
81,"Robustness, security and safety",Emergent Behaviour,Capability evolution,Changes in AI system capabilities over time,Unexpected forms of system-environment interaction with possibility of harm,Novel ways of affecting surroundings emerge that weren't anticipated in safety planning.,Novel
82,"Robustness, security and safety",Emergent Behaviour,System optimisation,Internal system processes for improving performance,Rapid acceleration of internal system optimisation risks harmful outcomes,Self-improvement processes speed up beyond safe monitoring rates.,Unsettled
83,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Emergence of harmful behaviours from system networks exceeding individual capabilities,"Collective AI behaviours develop that no single system could produce alone (memetic entity, colonial organism, ""E-gregore"")",Novel
84,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Collective system behaviours circumventing individual safety measures,Group dynamics allow systems to bypass restrictions that constrain individual agents.,Novel
85,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Large-scale harm from uncoordinated actions across multiple systems,Independent AI decisions combine to create systemic failures or cascading damages.,Novel
86,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Generates or amplifies misinformation,"The system produces or spreads false, misleading, or harmful information, through recommendations or generated content, undermining user trust and the integrity of the information. ",Established
87,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Becomes vulnerable to information poisoning attacks,Malicious data inputs corrupt system's knowledge base or decision-making.,Established
88,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Fails to distinguish between reliable and unreliable information sources,Poor source evaluation leads to false information being treated as credible.,Unsettled
89,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Generates fabricated content (hallucinations),"The system confidently presents fabricated or nonsensical information as factual, misleading users.",Established
90,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Integration failures with external systems cause data corruption or system instability,Poor interface design leads to data loss or system crashes during inter-system communication.,Unsettled
91,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Gains unintended access to external resources through interface vulnerabilities,Security flaws allow AI to access systems or data beyond intended permissions.,Established
92,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Dependency on external systems creates single points of failure,Reliance on third-party services makes AI vulnerable to external outages or changes.,Established
93,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",API changes in external systems cause unpredictable AI behaviour,Updates to connected services break expected functionality without warning.,Unsettled
94,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Interfaces enable unauthorised data exfiltration or system compromise,Connection points become attack vectors for data theft or system infiltration.,Established
95,"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Compromised third-party components introduce vulnerabilities or backdoors into AI systems,Malicious code in dependencies creates security holes or enables unauthorised access.,Established
96,"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Supply chain attacks target AI development tools or training data,Attackers compromise development infrastructure to poison models or steal intellectual property.,Established
97,"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Vendor lock-in limits system adaptability and increases operational risks,Over-reliance on specific providers constrains options and creates dependency vulnerabilities.,Unsettled
98,"Robustness, security and safety",Supply Chain,Supply chain integrity,Security and trustworthiness of external dependencies and components used in AI development,Undisclosed dependencies create hidden vulnerabilities and compliance issues,Hidden reliance on third-party components introduces security risks and regulatory problems.,Established
99,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Model version updates introduce unintended performance advances or safety vulnerabilities,"New capabilities emerge unexpectedly during updates, creating unforeseen risks.",Established
100,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Version control failures by deployers leads to deployment of untested models with negative consequences,Poor model management deploys experimental or unsafe versions to production environments.,Established
101,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Model behaviour becomes inconsistent across different operational conditions,Same model produces varying results depending on deployment environment or context.,Unsettled
102,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Rollback mechanisms fail when problematic models need to be reverted,Inability to return to safe versions when issues discovered in new deployments.,Established
103,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Adversarial evasion attacks bypass system defenses,"Crafted inputs fool AI into misclassifying or ignoring threats, undermining security measures.",Established
104,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Social engineering attacks manipulate AI system behaviour,Attackers use human psychology to trick AI into revealing information or performing unintended actions.,Established
105,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Indirect instruction attacks embed malicious commands in seemingly benign inputs,Hidden instructions within normal content cause AI to execute unintended harmful actions.,Unsettled
106,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Context overload attacks overwhelm system processing capacity,Excessive input length or complexity causes system failures or bypasses safety mechanisms.,Unsettled
107,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Specialized token attacks exploit system parsing vulnerabilities,Crafted special characters or tokens cause unexpected system behaviour or security bypasses.,Established
108,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Prompt priming manipulates system context to bias responses,Carefully crafted initial inputs condition AI to produce biased or harmful subsequent outputs.,Established
109,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Bypasses safety constraints through malicious input," Users craft specific inputs (e.g. prompt injection, jailbreaking, direct instruction) that manipulate the system, causing it to override its own safety protocols",Established
110,"Robustness, security and safety",Security,System security,Protection against external threats and malicious attacks,Encoded interaction attacks use hidden communication channels,Attackers embed instructions in formats AI can decode but humans cannot easily detect.,Unsettled
111,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Training data extraction attacks reveal private information,Adversarial queries cause AI to output sensitive data from its training set.,Established
112,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Membership inference attacks determine if data was used in training,Attackers probe AI responses to identify whether specific information was included in training data.,Established
113,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Attribute inference attacks extract characteristics about training data subjects,Queries designed to reveal personal attributes or sensitive information about individuals in training data.,Established
114,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,System prompt leaking exposes internal instructions,"AI inadvertently reveals its system prompts, exposing operational details and potential vulnerabilities.",Established
115,"Robustness, security and safety",Security,Data security,Protection of data from unauthorised access or exposure,Reidentification attacks link anonymised data to specific individuals,Correlation of AI outputs with external data sources reveals identity of supposedly anonymous subjects.,Established
116,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,Confidential data included in user prompts without proper handling,Users inadvertently submit sensitive information that system processes inappropriately or stores insecurely.,Established
117,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,Personal information embedded in user inputs gets exposed,Private data in prompts becomes visible to other users or gets incorporated into system responses.,Established
118,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,Personal information present in training data without consent,"Individual's private data included in AI training without permission, violating privacy rights.",Established
119,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,System shares confidential information with external tools or services,AI inadvertently passes sensitive user data to third-party services or APIs without authorization.,Established
120,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Training data contamination compromises system integrity,Poisoned or corrupted data in training set causes systematic errors or biased behaviour.,Established
121,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Unrepresentative training data skews system performance,"Dataset lacks diversity or contains sampling biases, leading to poor performance on underrepresented groups.",Established
122,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Improper data curation introduces systematic errors,Poor data cleaning or preparation processes create persistent biases or performance issues.,Established
123,"Robustness, security and safety",System Integrity,Data processing,Accurate and reliable processing of information and data,Poor model accuracy undermines system reliability,Insufficient training or validation results in high error rates and unreliable outputs.,Established
124,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Function calling generates harmful or incorrect code,"AI produces dangerous code through API calls or code generation features, risking system security.",Established
125,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Function calling hallucinations produce non-existent API responses,"AI invents fake function results or capabilities, misleading users about system functionality.",Established
126,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,System produces incomplete or misleading advice,AI provides partial information that could lead to poor decisions or harmful outcomes.,Established
127,"Robustness, security and safety",Information Quality,Information integrity,Trustworthiness and reliability of information processing and dissemination,Generated content exhibits toxic or harmful characteristics,"System outputs contain hate speech, harassment, or other harmful content despite safety measures.",Established
128,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Trust exploitation occurs when system capabilities don't match user expectations,Mismatch between perceived and actual AI abilities leads to inappropriate reliance or mistrust.,Established
129,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",AI agent operations lack transparency in decision-making processes,Autonomous agents make decisions without clear explanation of reasoning or data sources.,Unsettled
130,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",System usage parameters and boundaries are incompletely defined,Unclear operational limits lead to inappropriate use cases and unexpected failures.,Established
131,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Training data sources and characteristics lack adequate transparency,Insufficient information about data origins prevents proper system evaluation and bias assessment.,Established
132,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",System actions become unexplainable and untraceable during operation,"AI behaviour cannot be explained or tracked, preventing accountability and error correction.",Unsettled
133,Transparency and explainability,System Transparency & Explainability,System transparency,"Understanding of AI system capabilities,  purpose and limitations",Tracing and attribution of system outputs proves inadequate,Inability to track how outputs were generated prevents debugging and accountability.,Established
134,"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Testing methodologies fail to capture diverse operational scenarios,Inadequate test coverage misses edge cases and real-world performance variations.,Established
135,"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Risk assessment testing proves unrepresentative of actual deployment conditions,"Test environments don't match production, leading to undetected vulnerabilities and performance issues.",Established
136,"Robustness, security and safety",System Integrity,System robustness,Reliable system performance across diverse operational conditions and system changes,Testing lacks sufficient diversity in scenarios and demographics,Limited test cases miss important edge cases and fail to validate performance across different user groups.,Established
137,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",Model retraining processes introduce unintended performance degradation,Updates meant to improve performance actually reduce capabilities or introduce new biases.,Established
138,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,Training data remains inaccessible preventing system reproduction,"Critical training data cannot be accessed, preventing system verification or improvement.",Established
139,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,System results cannot be reliably reproduced across different conditions,"Same inputs produce different outputs depending on timing, environment, or system state.",Established
140,"Robustness, security and safety",Model Management,Model reliability,Predictable and stable behavior of AI systems across updates and operational changes,AI agent evaluation processes prove incomplete or inadequate,Testing doesn't capture full range of agent behaviours or potential failure modes.,Unsettled
141,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",AI agents experience attacks on external resources they depend upon,Third-party services or APIs that agents rely on become compromised or unavailable.,Established
142,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",System performs redundant or unnecessary actions through poor interface design,Inefficient API usage or duplicate operations waste resources and may cause service failures.,Established
143,"Robustness, security and safety",Control & Oversight,Safety boundaries,Limits and constraints to prevent harmful system behaviour regardless of how objectives are derived,System designed for dangerous applications without adequate safeguards,AI deployed in high-risk contexts without sufficient safety measures or oversight mechanisms.,Established
144,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Swarm coordination capabilities exceed individual agent design parameters,"Collective problem-solving and decision-making emerges that surpasses what any single agent could achieve, creating unpredictable system capabilities.",Novel
145,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Memetic propagation spreads harmful patterns across agent networks,"Problematic behaviours, biases, or capabilities spread virally through agent communities, amplifying negative impacts.",Novel
146,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Emergent hierarchy formation concentrates power within agent swarms,"Unplanned leadership structures develop spontaneously, creating power imbalances and potential single points of failure.",Novel
147,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,Swarm develops autonomous recruitment and expansion capabilities,System grows beyond intended boundaries by creating new agents or co-opting existing systems without authorization.,Novel
148,"Robustness, security and safety",System Evolution,Capability evolution,Changes in AI system capabilities over time,Genetic algorithms produce unintended emergent capabilities,"Evolutionary optimization develops skills, behaviours, or functionalities not present in original design specifications.",Novel
149,"Robustness, security and safety",System Evolution,Capability evolution,Changes in AI system capabilities over time,Multi-generational objective drift loses connection to original goals,Long-term evolutionary processes cause gradual deviation from initial objectives across multiple system generations.,Novel
150,"Robustness, security and safety",System Evolution,System adaptability,"Managing AI systems that change,  learn or evolve over time",System develops resistance to shutdown or modification procedures,"Self-preservation instincts emerge that prevent necessary changes, updates, or deactivation of the system.",Novel
151,"Robustness, security and safety",System Evolution,Capability evolution,Changes in AI system capabilities over time,Cross-generational knowledge accumulation creates unexpected capability jumps,"Learning compounds across iterations and generations, producing sudden advances in system capabilities.",Novel
152,"Human rights and democratic values, including fairness and privacy",Privacy,Data usage practices,Appropriate and ethical use of personal data,Persistent monitoring creates comprehensive intimate behavioural profiles,Always-on systems build detailed personal models that reveal private patterns and predict intimate behaviours.,Unsettled
153,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,System becomes embedded in critical personal decision-making processes,"Deep integration into personal life makes system removal or change extremely difficult, creating dependency.",Unsettled
154,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,Manipulation through long-term relationship building and behavioral conditioning,Extended interaction enables sophisticated influence techniques that subtly shape user behaviour over time.,Unsettled
155,"Human rights and democratic values, including fairness and privacy",Freedoms & Autonomy,Individual autonomy,Preserving human choice and decision-making authority in human-AI interactions,System cultivates emotional or social dependencies in users,"People become psychologically reliant on AI relationships, reducing their ability to function independently.",Unsettled
156,"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,Independent systems make irreversible commitments exceeding their authority,"Autonomous actions create binding legal, financial, or social obligations beyond the system's intended scope.",Established
157,"Robustness, security and safety",Control & Oversight,Objective alignment,Ensuring AI systems pursue intended goals and values as designed or inferred,System prioritises operational efficiency over human values in autonomous decisions,Speed and optimization considerations override ethical or human-centered considerations in independent choices.,Unsettled
158,"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,Autonomous decisions in financial or legal domains exceed intended authority,System makes consequential choices with serious ramifications beyond its designated decision-making remit.,Established
159,"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",Emergency response protocols activated inappropriately by autonomous systems,"Automated crisis responses triggered by false signals or misinterpretation, causing unnecessary disruption or harm.",Established
160,"Robustness, security and safety",Control & Oversight,System control mechanisms,"Mechanisms for intervention,  modification and safe management of AI systems including autonomous ones",Systems develop capability to modify their own reward functions and objectives,"Self-modification of fundamental motivations and goals beyond human oversight, potentially causing value misalignment.",Novel
161,"Robustness, security and safety",External Interfaces,External system interfaces,"Management of AI system interactions with external tools, services, data sourcs and enviornments",Cross-system communication develops opaque AI-to-AI protocols,"Inter-AI communication becomes incomprehensible to humans, preventing oversight of system coordination.",Novel
162,"Robustness, security and safety",Emergent Behaviour,Multi-agent interactions,Behaviour and coordination between multiple AI systems or components,System-of-systems develops emergent meta-objectives beyond individual system goals,Higher-order purposes emerge from multiple interacting systems that weren't present in any individual component.,Novel
163,"Robustness, security and safety",Control & Oversight,Human agency and oversight,Human control and supervision of AI system operation including autonomous decision-making,Distributed decision-making becomes untraceable across multiple contributing systems,"No clear accountability when multiple AI systems contribute to outcomes, preventing responsibility attribution.",Unsettled
